{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Message Passing for Quantum Chemistry\n",
    "\n",
    "Ref: https://arxiv.org/pdf/1704.01212.pdf\n",
    "\n",
    "Assumptions:\n",
    "1. Hidden states for atoms are not updated (only for atoms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkretov/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import deepchem as dc\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import Variable\n",
    "from rdkit import Chem, DataStructs\n",
    "\n",
    "from data import prepare_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(2)\n",
    "torch.manual_seed(2)\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET = 'data.csv'\n",
    "T = 3\n",
    "BATCH_SIZE = 2\n",
    "MAXITER = 40000\n",
    "LIMIT = 0\n",
    "LR = 5e-4\n",
    "NUM_ATOM_FEAT = 75\n",
    "NUM_EDGE_FEAT = 6\n",
    "HID_SIZE_ATOM = 25\n",
    "HID_SIZE_EDGE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuncM(nn.Module):\n",
    "    \"\"\"\n",
    "    Message passing function (M_t in ref. article) in the form of MLP.\n",
    "    Takes as input concatenated vector of [hid state of atom, hid state of neighbour atom, hid state of edge].\n",
    "    Return new candidate state \"m\" for atom.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, inp_atom_features, inp_edge_features, out_size_atom, hidden=[]):\n",
    "        super(FuncM, self).__init__()\n",
    "        self.inp_atom = inp_atom_features\n",
    "        self.inp_edge = inp_edge_features\n",
    "        self.out_atom = out_size_atom\n",
    "        self.hidden = hidden\n",
    "        \n",
    "    def forward(self, x):\n",
    "        inp_size = self.inp_atom * 2 + self.inp_edge\n",
    "        for hid in self.hidden:\n",
    "            out = nn.Linear(inp_size, hid)\n",
    "            out = F.relu(out)\n",
    "            inp_size = hid\n",
    "        return nn.Linear(inp_size, self.out_atom)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuncU(nn.Module):\n",
    "    \"\"\"\n",
    "    Vertex update function (U_t in the ref. article) in the form of MLP.\n",
    "    Takes as input concatenated vector of [his state of atom, calculated candidate M state of atom]\n",
    "    \"\"\"\n",
    "    def __init__(self, inp_atom_features, inp_atom_m_state, out_size_atom, hidden=[])\n",
    "        super(FuncU, self).__init__()\n",
    "        self.inp_atom = inp_atom_features\n",
    "        self.inp_m_atom = inp_atom_m_state\n",
    "        self.out_atom = out_size_atom\n",
    "        self.hidden = hidden\n",
    "        \n",
    "    def forward(self, x):\n",
    "        inp_size = self.inp_atom * 2 + self.inp_edge\n",
    "        for hid in self.hidden:\n",
    "            out = nn.Linear(inp_size, hid)\n",
    "            out = F.relu(out)\n",
    "            inp_size = hid\n",
    "        return nn.Linear(inp_size, self.out_atom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FuncR(nn.Module):\n",
    "    \"\"\"\n",
    "    Readout function (R in ref.article).\n",
    "    Takes as input hidden states of atom in the form (N_atoms, N_features)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MPNN:\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = nn.Linear(150, 128)   # function R\n",
    "U = {0: nn.Linear(156, 75), 1: nn.Linear(156, 75), 2: nn.Linear(156, 75)}  # function M\n",
    "V = {0: nn.Linear(75, 75), 1: nn.Linear(75, 75), 2: nn.Linear(75, 75)}  # function U (but without edge features)\n",
    "E = nn.Linear(6, 6)  # function U (but without atom features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readout(h, h2):\n",
    "    catted_reads = map(lambda x: torch.cat([h[x[0]], h2[x[1]]], 1), zip(h2.keys(), h.keys()))\n",
    "    activated_reads = map(lambda x: F.selu(R(x)), catted_reads)\n",
    "    readout = Variable(torch.zeros(1, 128))\n",
    "    for read in activated_reads:\n",
    "        readout = readout + read\n",
    "    return F.tanh(readout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def message_pass(g, h, k):\n",
    "    for v in g.keys():\n",
    "        neighbors = g[v]\n",
    "        for neighbor in neighbors:\n",
    "            e_vw = neighbor[0]  # edge feature variable\n",
    "            w = neighbor[1]  # number of connected atom\n",
    "            m_w = V[k](h[w])  # calc hidden variable of atom\n",
    "            m_e_vw = E(e_vw)  # calc hidden variable of edge \n",
    "            reshaped = torch.cat((h[v], m_w, m_e_vw), 1)  # calculating concatenated hid states of atoms and edge\n",
    "            h[v] = F.selu(U[k](reshaped))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_features(smile):\n",
    "    \"\"\"\n",
    "    Get input features for edges (g) and atoms (h).\n",
    "    \"\"\"\n",
    "    g = OrderedDict({})\n",
    "    h = OrderedDict({})\n",
    "    molecule = Chem.MolFromSmiles(smile)\n",
    "    for i in range(0, molecule.GetNumAtoms()):\n",
    "        atom_i = molecule.GetAtomWithIdx(i)\n",
    "        h[i] = Variable(torch.FloatTensor(dc.feat.graph_features.atom_features(atom_i).astype(np.float32))).view(1, 75)  # mk: added astype\n",
    "        for j in range(0, molecule.GetNumAtoms()):\n",
    "            e_ij = molecule.GetBondBetweenAtoms(i, j)\n",
    "            if e_ij != None:\n",
    "                e_ij = list(map(lambda x: 1 if x == True else 0,    # mk: added list\n",
    "                           dc.feat.graph_features.bond_features(e_ij)))  # ADDED edge feat\n",
    "                e_ij = Variable(torch.FloatTensor(e_ij).view(1, 6))\n",
    "                atom_j = molecule.GetAtomWithIdx(j)\n",
    "                if i not in g:\n",
    "                    g[i] = []\n",
    "                    g[i].append((e_ij, j))\n",
    "    return g, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_smiles, train_labels, val_smiles, val_labels = prepare_datasets(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear = nn.Linear(128, 1)\n",
    "params = [{'params': R.parameters()},\n",
    "         {'params': U[0].parameters()},\n",
    "         {'params': U[1].parameters()},\n",
    "         {'params': U[2].parameters()},\n",
    "         {'params': E.parameters()},\n",
    "         {'params': V[0].parameters()},\n",
    "         {'params': V[1].parameters()},\n",
    "         {'params': V[2].parameters()},\n",
    "         {'params': linear.parameters()}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epoch = 0\n",
    "optimizer = optim.Adam(params, lr=LR, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, MAXITER):\n",
    "    optimizer.zero_grad()\n",
    "    train_loss = Variable(torch.zeros(1, 1))\n",
    "    y_hats_train = []\n",
    "    for j in range(0, BATCH_SIZE):\n",
    "        sample_index = random.randint(0, len(train_smiles) - 2)\n",
    "        smile = train_smiles[sample_index]\n",
    "        g, h = get_input_features(smile)  # TODO: cache this\n",
    "\n",
    "        g2, h2 = get_input_features(smile)\n",
    "\n",
    "        for k in range(0, T):\n",
    "            message_pass(g, h, k)\n",
    "\n",
    "        x = readout(h, h2)\n",
    "        # x = F.selu( fc(x) )\n",
    "        y_hat = linear(x)\n",
    "        y = train_labels[sample_index]\n",
    "\n",
    "        y_hats_train.append(y_hat)\n",
    "\n",
    "        error = (y_hat - y) * (y_hat - y) / Variable(torch.FloatTensor([BATCH_SIZE])).view(1, 1)\n",
    "        train_loss = train_loss + error\n",
    "\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    if i % 10 == 0: #int(len(train_smiles) / BATCH_SIZE) == 0:\n",
    "        val_loss = Variable(torch.zeros(1, 1), requires_grad=False)\n",
    "        y_hats_val = []\n",
    "        for j in range(0, len(val_smiles)):\n",
    "            g, h = get_input_features(val_smiles[j])\n",
    "            g2, h2 = get_input_features(val_smiles[j])\n",
    "\n",
    "            for k in range(0, T):\n",
    "                message_pass(g, h, k)\n",
    "\n",
    "            x = readout(h, h2)\n",
    "            # x = F.selu( fc(x) )\n",
    "            y_hat = linear(x)\n",
    "            y = val_labels[j]\n",
    "\n",
    "            y_hats_val.append(y_hat)\n",
    "\n",
    "            error = (y_hat - y) * (y_hat - y) / Variable(torch.FloatTensor([len(val_smiles)])).view(1, 1)\n",
    "            val_loss = val_loss + error\n",
    "\n",
    "        y_hats_val = np.array(list(map(lambda x: x.data.numpy(), y_hats_val)))\n",
    "        y_val = np.array(list(map(lambda x: x.data.numpy(), val_labels)))\n",
    "        y_hats_val = y_hats_val.reshape(-1, 1)\n",
    "        y_val = y_val.reshape(-1, 1)\n",
    "\n",
    "        r2_val_old = r2_score(y_val, y_hats_val)\n",
    "        r2_val_new = pearsonr(y_val, y_hats_val)[0][0] ** 2\n",
    "\n",
    "        train_loss_ = train_loss.data.numpy()[0][0]\n",
    "        val_loss_ = val_loss.data.numpy()[0][0]\n",
    "        print('epoch [{}/{}] train_loss [{}] val_loss [{}] r2_val_old [{}], r2_val_new [{}]'.format(num_epoch, 100, train_loss_, val_loss_, r2_val_old, r2_val_new))\n",
    "        num_epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_epoch, 100, train_loss_, val_loss_, r2_val_old, r2_val_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(y_val, y_hats_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val == y_hats_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = Variable(torch.zeros(1, 1), requires_grad=False)\n",
    "y_hats_val = []\n",
    "for j in range(0, len(val_smiles)):\n",
    "    g, h = get_input_features(val_smiles[j])\n",
    "    g2, h2 = get_input_features(val_smiles[j])\n",
    "\n",
    "    for k in range(0, T):\n",
    "        message_pass(g, h, k)\n",
    "\n",
    "    x = readout(h, h2)\n",
    "    # x = F.selu( fc(x) )\n",
    "    y_hat = linear(x)\n",
    "    y = val_labels[j]\n",
    "\n",
    "    y_hats_val.append(y_hat)\n",
    "\n",
    "    error = (y_hat - y) * (y_hat - y) / Variable(torch.FloatTensor([len(val_smiles)])).view(1, 1)\n",
    "    val_loss = val_loss + error\n",
    "\n",
    "y_hats_val = np.array(list(map(lambda x: x.data.numpy(), y_hats_val)))\n",
    "y_val = np.array(list(map(lambda x: x.data.numpy(), val_labels)))\n",
    "y_hats_val = y_hats_val.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "\n",
    "r2_val_old = r2_score(y_val, y_hats_val)\n",
    "r2_val_new = pearsonr(y_val, y_hats_val)[0][0] ** 2\n",
    "\n",
    "train_loss_ = train_loss.data.numpy()[0][0]\n",
    "val_loss_ = val_loss.data.numpy()[0][0]\n",
    "print('epoch [{}/{}] train_loss [{}] val_loss [{}] r2_val_old [{}], r2_val_new [{}]'.format(num_epoch, 100, train_loss_, val_loss_, r2_val_old, r2_val_new))\n",
    "num_epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(y_val, y_hats_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
